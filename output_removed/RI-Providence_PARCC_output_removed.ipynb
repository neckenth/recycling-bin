{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from pyep.settings import WORKSPACE_ROOT\n",
      "\n",
      "def main():\n",
      "    db_name = 'ESLREPS-RI-PROVIDENCE'\n",
      "    district = 'ri-providence'\n",
      "    source_file_name = 'PPSD_PARCC_SY1516_ELLCENSUS_MATCH.csv'\n",
      "    \n",
      "    file_name = '{}/{}/standardized-tests/{}'.format(WORKSPACE_ROOT, district, source_file_name)\n",
      "    source = pd.read_csv(file_name)\n",
      "    \n",
      "    domains = ['ALG01', 'GEO01', 'MAT', 'ELA']\n",
      "    \n",
      "    test_type_mapping = {\n",
      "        'ALG01': 'Algebra I',\n",
      "        'GEO01': 'Geometry',\n",
      "        'MAT': 'Mathematics', \n",
      "        'ELA': 'ELA/Literacy'\n",
      "    }\n",
      "    \n",
      "    test_subject_mapping = {\n",
      "        'ALG01' : 'Math',\n",
      "        'GEO01' : 'Math',\n",
      "        'MAT' : 'Math',\n",
      "        'ELA' : 'ELA'\n",
      "    }\n",
      "    \n",
      "    performance_level_mapping = {\n",
      "        '1' : 'Level 1: Did not yet meet expectations',\n",
      "        '2' : 'Level 2: Partially met expectations',\n",
      "        '3' : 'Level 3: Approached expectations',\n",
      "        '4' : 'Level 4: Met expectations',\n",
      "        '5' : 'Level 5: Exceeded expectations'\n",
      "        \n",
      "    }\n",
      "    \n",
      "    subset = []\n",
      "    \n",
      "    for domain in domains:\n",
      "        df = source[['\\xef\\xbb\\xbfSASID',\n",
      "                     'GRADE',\n",
      "                    'TESTDATE',\n",
      "                    'PARCC_{}_SS_max'.format(domain),\n",
      "                    'PARCC_{}_Level_max'.format(domain)]]\n",
      "        \n",
      "        df.loc[:, 'StudentTestID'] = source.loc[:, '\\xef\\xbb\\xbfSASID']\n",
      "        df.loc[:, 'StudentGradeLevel'] = source.loc[:, 'GRADE']\n",
      "        df.loc[:, 'TestGradeLevel'] = source.loc[:, 'GRADE']\n",
      "        df.loc[:, 'TestAdministrationDate'] = source.loc[:, 'TESTDATE']\n",
      "        df.loc[:, 'TestTypeName'] = 'PARCC ' + (test_type_mapping[domain])\n",
      "        df.loc[:, 'TestSubjectName'] = (test_subject_mapping[domain])\n",
      "        df.loc[:, 'Score1Value'] = source.loc[:, 'PARCC_{}_SS_max'.format(domain)]\n",
      "        df.loc[:, 'Score2Value'] = source.loc[:, 'PARCC_{}_Level_max'.format(domain)].map(performance_level_mapping)\n",
      "        \n",
      "        subset.append(df)\n",
      "        \n",
      "    df = pd.concat(subset)\n",
      "    \n",
      "    df.loc[:, 'DistrictDBName'] = db_name\n",
      "    df.loc[:, 'StudentLocalID'] = np.NaN\n",
      "    df.loc[:, 'TestID'] = 0\n",
      "    df.loc[:, 'TestName'] = 'PARCC'\n",
      "    df.loc[:, 'TestTypeID'] = 0\n",
      "    df.loc[:, 'TestSubjectID'] = 0\n",
      "    df.loc[:, 'Score1Label'] = 'Score'\n",
      "    df.loc[:, 'Score1Type'] = 'Scale'\n",
      "    df.loc[:, 'Score2Label'] = 'Performance Level'\n",
      "    df.loc[:, 'Score2Type'] = 'Level'\n",
      "    df.loc[:, 'SourceFileName'] = source_file_name\n",
      "    \n",
      "    headers = ['DistrictDBName',\n",
      "            'StudentTestID',\n",
      "            'StudentLocalID',\n",
      "            'StudentGradeLevel',\n",
      "            'TestAdministrationDate',\n",
      "            'TestID',\n",
      "            'TestName',\n",
      "            'TestTypeID',\n",
      "            'TestTypeName',\n",
      "            'TestSubjectID',\n",
      "            'TestSubjectName',\n",
      "            'TestGradeLevel',\n",
      "            'Score1Label',\n",
      "            'Score1Type',\n",
      "            'Score1Value',\n",
      "            'Score2Label',\n",
      "            'Score2Type',\n",
      "            'Score2Value',\n",
      "            'Score3Label',\n",
      "            'Score3Type',\n",
      "            'Score3Value',\n",
      "            'Score4Label',\n",
      "            'Score4Type',\n",
      "            'Score4Value',\n",
      "            'Score5Label',\n",
      "            'Score5Type',\n",
      "            'Score5Value',\n",
      "            'Score6Label',\n",
      "            'Score6Type',\n",
      "            'Score6Value',\n",
      "            'Score7Label',\n",
      "            'Score7Type',\n",
      "            'Score7Value',\n",
      "            'Score8Label',\n",
      "            'Score8Type',\n",
      "            'Score8Value',\n",
      "            'SourceFileName']\n",
      "    \n",
      "    print len(df)\n",
      "    \n",
      "    df = df[df.loc[:, 'Score1Value'].notnull() & df.loc[:, 'Score2Value'].notnull()]\n",
      "    \n",
      "    print len(df)\n",
      "    \n",
      "    df.loc[:, headers].to_csv(r\"C:\\Workspace\\ri-providence\\standardized-tests\\ELLSTDTST_RI-Providence_PARCC_15-16.csv\", index=False)\n",
      "    \n",
      "main()\n",
      "                  \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}